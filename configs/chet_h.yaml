seed: 6669
dataset: mimic3
task: h
use_cuda: true
code_size: 48
graph_size: 32
hidden_size: 100
t_attention_size: 32
pretrained_embeddings_path: null
freeze_embeddings: false
graph_layer_type: gcn
dropout: 0.0
# train config
batch_size: 32
epochs: 200
output_dir: "./runs/chet_" # output directory for saving checkpoints
lr: 0.01
milestones:
  - 2
  - 3
  - 20
lrs:
  - 0.001
  - 0.0001
  - 0.00001

lr_scheduler: "multi_step"